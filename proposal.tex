\documentclass[letterpaper,11pt]{article}

%% AMS mathematics packages - they contain many useful fonts and symbols.
\usepackage{amsmath, amsfonts, amssymb, bm, amsthm}

%% The geometry package changes the margins to use more of the page, I suggest
%% using it because standard latex margins are chosen for articles and letters,
%% not homework.
\usepackage[paper=letterpaper,left=25mm,right=25mm,top=30mm,bottom=30mm]{geometry}
%% For details of how this package work, google the ``latex geometry documentation''.

\usepackage{graphicx}

\setlength{\headheight}{15pt}

%%%%%%
%% The above stuff is the same as the first template, but now we are starting to prove things, so we'd like to have a
%% good proof environment that gives us nice formatting and a little square at the end.
%% We'd also like a nice Result environment that prints that up nicely too.
%% Thankfully this exists in latex in the amsthm package
\usepackage{amsthm}
\newtheorem*{thm}{Theorem}
%% This creates a new theorem-like environment called "result", that will be titled "Result".
%% See below for examples of how to use this.
%%%%%%
\usepackage{enumitem}
%% This package allows us to make nice ordered lists with numbers, letters or roman numerals

\usepackage{titlesec}
% \titlespacing*{\subsection}{0pt}{0pt}{3.0ex}
% \titlespacing*{\subsubsection}{0pt}{3.0ex}{0.5ex}

\usepackage[hang,flushmargin]{footmisc}

\setlength{\parindent}{0em}
\setlength{\parskip}{0.5em}

\allowdisplaybreaks

\usepackage{empheq}

\newcommand*\wfbox[1]{\fbox{\hspace{0.4em}#1\hspace{0.4em}}}

%% Useful commands
\renewcommand*{\qed}{\hfill\ensuremath{\square}}

\newcommand*{\uvec}[1]{\hat{\bm{#1}}}

\newcommand*{\deriv}[2]{\frac{d #1}{d #2}}
\newcommand*{\pderiv}[2]{\frac{\partial #1}{\partial #2}}
\newcommand*{\nderiv}[3]{\frac{d^{#3} #1}{d #2^{#3}}}
\newcommand*{\npderiv}[3]{\frac{\partial^{#3} #1}{\partial #2^{#3}}}
\newcommand*{\divg}[1]{\nabla \cdot \mathbf{#1}}
\newcommand*{\curl}[1]{\nabla \times \mathbf{#1}}

\newcommand*{\abs}[1]{\left| #1 \right|}
\newcommand*{\norm}[1]{\abs{\abs{\mathbf{#1}}}}

\renewcommand*{\Re}[1]{\text{Re}\left(#1\right)}
\renewcommand*{\Im}[1]{\text{Im}\left(#1\right)}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\newcommand*{\qimg}[2]{\\ \begin{center}\includegraphics[scale=#1]{#2}\end{center}}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}{Corollary}[theorem]

%%

\title{$y$-adaptive Gradient Descent}
\author{James Wu \quad 92277235}
\date{}

\begin{document}
\maketitle
\begin{flushleft}
    
    \section{Background}
    In one of my condensed matter physics research projects, I am looking to fit a vector of paramters $\mathbf{v}$ to describe the interactions of a quantum mechanical system (the system is parametrized by $\mathbf{v}$). There is another vector of real numbers $\mathbf{k}$ (the system's momentum) that also parametrizes the system. Now, the system's ground state energy $E_0(\mathbf{v}, \mathbf{k})$ is to be matched with target energies $E_T(\mathbf{k})$. This is done by interpolating for a finite number of $\mathbf{k}$ points (in practice this seems to match $E_T(\mathbf{k})$ for all $\mathbf{k}$ quite well). One way to find an appropriate $\mathbf{v}$ is to use gradient descent on the cost function
    $$J(\mathbf{v}) = \norm{\mathbf{E_0}(\mathbf{v}) - \mathbf{E_T}}_2$$
    Here $\mathbf{E_0}$ and $\mathbf{E_T}$ are vectors with entries that are energy values at various $\mathbf{k}$ values. In short, we use a least squares fit. $E_0(\mathbf{v}, \mathbf{k})$ can computed as the energy where the \textit{spectral density function} $A(E)$ spikes. For example, in the following figure, we see that $E \approx -9.1$:
    \qimg{0.8}{img/spec.jpg}
    Numerically, we restrict ourselves to an interval $I$ with $N$ evenly spaced grid points to evaluate $A(E)$. We thus have
    $$E_0(\mathbf{v}, \mathbf{k}) = \argmax_{E \in I} A(E, \mathbf{v}, \mathbf{k})$$
    There is another parameter $\eta$, which controls the spikes width, that is set equal to the grid spacing $dE$ to ensure that the spike will be detected. Locally, this spike is symmetric (a Lorentzian, in fact) in the limit $\eta \to 0^+$. So the error in this method is roughly bounded by $dE/2$. This error propagates to the $J(\mathbf{v})$ function to also produce an error bound of $dE/2$ if we use a dimensionality-agnostic 2-norm (i.e. divide by the square root of the dimension of the energy vectors).

    In the following analyses, we consider single-variable functions for simplicity. Let $f(x)$ be such a function that we are interested in and $g(x) = f(x) + \delta(x)$ be a noisy function with $|\delta(x)| \leq \Delta$ for some positive error bound $\Delta$ (e.g. $\Delta = dE/2$).

    To motivate this project, I seek to answer the question of how $\Delta$ should be scaled relative to the other numerical parameters to obtain the best accuracy for the least computation time. I will therefore be determining the asymptotic errors for various numerical methods for a given number of computations.

    \section{Finite Difference}

    \subsection{First Derivative: Central Difference}
    Suppose we want to compute the derivative of $f(x)$ but only have access to evaluating the noisy function $g(x)$. A central difference yields:
    $$f'(a) \approx \frac{g(a+k) - g(a-k)}{2k}$$
    The error in this method is
    \begin{align*}
        f'(a) - \frac{g(a+k) - g(a-k)}{2k} &= f'(a) - \frac{f(a+k) - f(a-k)}{2k} - \frac{\delta(a+k) - \delta(a-k)}{2k} \\
        &= -\frac{1}{12}f'''(\xi)k^2 + \frac{1}{12}f'''(\zeta)k^2 - \frac{\delta(a+k) - \delta(a-k)}{2k}
    \end{align*}
    for some $\xi \in (a, a+k)$ and $\zeta \in (a-k, a)$. A bound for this error $E(k, \Delta)$ is then
    $$E(k, \Delta) = \frac{1}{6}K_3k^2 + \frac{\Delta}{k}$$
    where $K_3$ is a bound on the third derivative of $f(x)$. Note that Taylor analysis is not applied to $\delta(x)$ because it is not continuous--$\delta(x)$ is discretized, for example, in the spectral density function case.
    
    Now, the computation time $C(k, \Delta)$ is independent of $k$ because only a single finite difference is computed. $C(k, \Delta)$ is inversely proportional to $\Delta$ in the spectral density function scenario, however, because the number of $A(E)$ evaluations for a given interval size $|I|$ is approximately $|I|/dE$:
    $$\boxed{C(k, \Delta) \sim \Delta^{-1}}$$
    The optimal $k$ that produces a minimal error bound given a fixed $C(k, \Delta)$ and therefore fixed $\Delta$ is given by
    \begin{align*}
        \deriv{E}{k} &= \pderiv{E}{k} = \frac{1}{3}K_3k - \frac{\Delta}{k^2} = 0
    \end{align*}
    So the optimal $k$-$\Delta$ relationship is
    $$\boxed{\Delta = \frac{1}{3}K_3k^3}$$
    The cubic relationship makes sense because the $\frac{1}{6}K_3k^2$ and $\frac{\Delta}{k}$ terms in $E(k, \Delta)$ should scale the same--if they did not, the term that vanishes the slowest would become a bottleneck and could be made smaller for faster error convergence. The error bound is then
    $$\boxed{E(k, \Delta) = \frac{1}{2}K_3k^3 = \frac{3^{2/3}}{2}K_3^{2/3}\Delta^{2/3}}$$
    The error bounds scales with the comptuation time as:
    $$\boxed{E \sim C^{-2/3}}$$

\end{flushleft}
\end{document}
